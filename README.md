# SIGN-LANGUAGE-DETECTION

I've added a Jupyter Notebook to the project that implements sign language detection using a YOLOv8 model. The notebook is designed to capture and classify hand gestures in real-time, with labels including 'hello', 'thanks', 'yes', 'no', and 'iloveyou'. Each label is represented by 15 images collected for training purposes. The project also has been updated to work smoothly in PyCharm, allowing for efficient real-time detection and classification of sign language gestures.
